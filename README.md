# recommandation-contenu 

Ce projet impl√©mente un syst√®me de recommandation de contenu (articles, livres) de bout en bout, incluant l'entra√Ænement de mod√®les, une interface utilisateur interactive et un pipeline de r√©-entra√Ænement automatis√©.

## üöÄ Fonctionnalit√©s

* **Mod√®le Hybride Sophistiqu√©** : Combine le **filtrage collaboratif** (bas√© sur les interactions des utilisateurs) et le **filtrage bas√© sur le contenu** (bas√© sur la similarit√© s√©mantique des articles) pour des recommandations pertinentes.
* **Gestion du "Cold Start"** : Fournit des recommandations bas√©es sur la popularit√© pour les nouveaux utilisateurs.
* **Interface Utilisateur Interactive** : Une application **Streamlit** permet aux utilisateurs de cr√©er un compte et d'obtenir des recommandations personnalis√©es.
* **API D√©di√©e** : Les pr√©dictions du mod√®le sont servies via une API **FastAPI**, d√©couplant le front-end du back-end de machine learning.
* **Automatisation MLOps** : Un workflow **GitHub Actions** r√©-entra√Æne automatiquement le mod√®le chaque semaine et le d√©ploie sur Azure Blob Storage, garantissant que le syst√®me reste √† jour.
* **Stockage Cloud** : Les donn√©es, les mod√®les et les informations utilisateurs sont stock√©s sur **Azure Blob Storage**.

## üèõÔ∏è Architecture

Le projet est structur√© en trois composants principaux :

1. **Pipeline d'Entra√Ænement (`reco_model_script.py`)**

   * Charge les donn√©es brutes (clics, m√©tadonn√©es, embeddings) depuis Azure.
   * Entra√Æne un mod√®le hybride qui pond√®re les scores d'un mod√®le SVDpp (collaboratif) et d'un mod√®le Content-Based (avec d√©croissance temporelle).
   * Sauvegarde le pipeline de mod√®le finalis√© dans un fichier `hybrid_recommender_pipeline.pkl`.
2. **API de Recommandation (bas√©e sur FastAPI - non incluse dans ce d√©p√¥t)**

   * Charge le mod√®le `.pkl` sauvegard√©.
   * Expose un endpoint `/recommendations/` qui accepte un `user_id` et retourne une liste d'articles recommand√©s.
3. **Application Web (`app.py`)**

   * Fournit une interface utilisateur construite avec Streamlit.
   * Communique avec l'API FastAPI pour r√©cup√©rer et afficher les recommandations.
   * Permet la cr√©ation de nouveaux utilisateurs, en sauvegardant les informations sur Azure.

Le workflow **GitHub Actions (`retrain_model.yml`)** orchestre ce processus en ex√©cutant p√©riodiquement le script d'entra√Ænement et en t√©l√©versant le nouveau mod√®le sur Azure, o√π l'API peut le charger.

---

## üõ†Ô∏è Installation et Lancement

### Pr√©requis

* Python 3.9 ou sup√©rieur
* Un compte Azure avec un conteneur de stockage Blob.

### 1. Cloner le D√©p√¥t

```bash
git clone https://github.com/emmanuelouedraogo/recommandation-contenu.git
cd recommandation-contenu
```

### 2. Installer les D√©pendances

Il est recommand√© d'utiliser un environnement virtuel.

```bash
python -m venv venv
source venv/bin/activate  # Sur Windows: venv\Scripts\activate
pip install -r requirements.txt
```

### 3. Configurer les Secrets

Pour que l'application fonctionne, vous devez configurer les secrets n√©cessaires.

#### Pour l'Application Streamlit

Cr√©ez un fichier `.streamlit/secrets.toml` avec le contenu suivant :

```toml
# .streamlit/secrets.toml

AZURE_CONNECTION_STRING = "votre_chaine_de_connexion_azure"
API_URL = "http://adresse_de_votre_api_fastapi:8000"
```

#### Pour le Workflow GitHub Actions

Dans votre d√©p√¥t GitHub, allez dans `Settings` > `Secrets and variables` > `Actions` et ajoutez les secrets suivants :

* `AZURE_CONNECTION_STRING` : Votre cha√Æne de connexion Azure.

### 4. Lancer l'Application Streamlit

Assurez-vous que votre API FastAPI est en cours d'ex√©cution, puis lancez l'application Streamlit :

```bash
streamlit run app.py
```

Ouvrez votre navigateur √† l'adresse indiqu√©e (g√©n√©ralement `http://localhost:8501`).

---

## üîÑ Pipeline de R√©-entra√Ænement

Le fichier `.github/workflows/retrain_model.yml` d√©finit le pipeline CI/CD.

* **D√©clenchement** :
  * **Manuel** : Peut √™tre lanc√© √† tout moment depuis l'onglet "Actions" de GitHub.
  * **Automatique** : S'ex√©cute tous les dimanches √† 2h00 du matin (UTC).
* **Processus** :
  1. R√©cup√®re le code source.
  2. Installe les d√©pendances Python.
  3. Ex√©cute le script `reco_model_script.py` pour g√©n√©rer un nouveau fichier `save/hybrid_recommender_pipeline.pkl`.
  4. T√©l√©verse ce fichier `.pkl` comme artefact de l'action pour l'archivage.
  5. D√©ploie le nouveau mod√®le sur Azure Blob Storage, √©crasant la version pr√©c√©dente.

Ce m√©canisme garantit que l'API de recommandation utilise toujours la version la plus r√©cente du mod√®le sans aucune interruption de service.
